{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644c08d-f6bd-48c9-a985-85950ea78ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to pip install jupyter first\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3426f96-2730-4f79-a95d-05758638d439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:05.512976Z",
     "iopub.status.busy": "2024-03-20T11:37:05.512440Z",
     "iopub.status.idle": "2024-03-20T11:37:05.546788Z",
     "shell.execute_reply": "2024-03-20T11:37:05.546009Z",
     "shell.execute_reply.started": "2024-03-20T11:37:05.512930Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbee7830-1cb1-45c8-b426-ec6cd19f1858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:09.451198Z",
     "iopub.status.busy": "2024-03-20T11:37:09.450581Z",
     "iopub.status.idle": "2024-03-20T11:37:09.511791Z",
     "shell.execute_reply": "2024-03-20T11:37:09.510830Z",
     "shell.execute_reply.started": "2024-03-20T11:37:09.451146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cbee53-5f62-4461-80a3-32e3cb15d36b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad3edaf-27c5-45cb-a92f-1e85f85c73a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:10.557939Z",
     "iopub.status.busy": "2024-03-20T11:37:10.556807Z",
     "iopub.status.idle": "2024-03-20T11:37:11.185343Z",
     "shell.execute_reply": "2024-03-20T11:37:11.183787Z",
     "shell.execute_reply.started": "2024-03-20T11:37:10.557887Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81def16e-7fda-4a98-a656-29ffc7457f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:11.187693Z",
     "iopub.status.busy": "2024-03-20T11:37:11.187241Z",
     "iopub.status.idle": "2024-03-20T11:37:11.209915Z",
     "shell.execute_reply": "2024-03-20T11:37:11.209075Z",
     "shell.execute_reply.started": "2024-03-20T11:37:11.187662Z"
    }
   },
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"../raw_data/dummy_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6274dd-b95e-45dd-9b8a-a4edb60a1e43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:11.211389Z",
     "iopub.status.busy": "2024-03-20T11:37:11.210927Z",
     "iopub.status.idle": "2024-03-20T11:37:11.244733Z",
     "shell.execute_reply": "2024-03-20T11:37:11.243974Z",
     "shell.execute_reply.started": "2024-03-20T11:37:11.211361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 4) Index(['Product Name', 'Product Description', 'Review Text', 'Rating'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone 15</td>\n",
       "      <td>The Apple iPhone 15 redefines smartphone innov...</td>\n",
       "      <td>The iPhone 15 is a masterpiece! The sleek desi...</td>\n",
       "      <td>{\"durability\": 5, \"ease of use\": 5, \"pleasant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MacBook Pro 2023</td>\n",
       "      <td>Experience the ultimate in computing power wit...</td>\n",
       "      <td>The MacBook Pro 2023 is a game-changer! The pe...</td>\n",
       "      <td>{\"durability\": 5, \"ease of use\": 5, \"pleasant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kindle Paperwhite</td>\n",
       "      <td>Enjoy reading your favorite books anytime, any...</td>\n",
       "      <td>The Kindle Paperwhite is a must-have for book ...</td>\n",
       "      <td>{\"durability\": 5, \"ease of use\": 5, \"pleasant ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product Name                                Product Description  \\\n",
       "0          iPhone 15  The Apple iPhone 15 redefines smartphone innov...   \n",
       "1   MacBook Pro 2023  Experience the ultimate in computing power wit...   \n",
       "2  Kindle Paperwhite  Enjoy reading your favorite books anytime, any...   \n",
       "\n",
       "                                         Review Text  \\\n",
       "0  The iPhone 15 is a masterpiece! The sleek desi...   \n",
       "1  The MacBook Pro 2023 is a game-changer! The pe...   \n",
       "2  The Kindle Paperwhite is a must-have for book ...   \n",
       "\n",
       "                                              Rating  \n",
       "0  {\"durability\": 5, \"ease of use\": 5, \"pleasant ...  \n",
       "1  {\"durability\": 5, \"ease of use\": 5, \"pleasant ...  \n",
       "2  {\"durability\": 5, \"ease of use\": 5, \"pleasant ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_reviews.shape, df_reviews.columns)\n",
    "df_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a477c813-8993-45b5-8661-45415aa22c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:11.891409Z",
     "iopub.status.busy": "2024-03-20T11:37:11.890961Z",
     "iopub.status.idle": "2024-03-20T11:37:11.914080Z",
     "shell.execute_reply": "2024-03-20T11:37:11.912996Z",
     "shell.execute_reply.started": "2024-03-20T11:37:11.891375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google Nest Learning Thermostat'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out some descriptions to use as input\n",
    "df_reviews[\"Product Name\"].sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433a24f-4c86-4937-9ae6-0e6b90217864",
   "metadata": {},
   "source": [
    "## Criteria generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3da2a-fac7-4aec-be78-8c9396d1bdd6",
   "metadata": {},
   "source": [
    "### A) Langchain - OpenAI\n",
    "\n",
    "Le Wagon's requirements file for using LangChain: https://wagon-public-datasets.s3.amazonaws.com/deep_learning_datasets/langchain_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6e097a-a0d4-4e38-b49e-b9cf1a522f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:37.620620Z",
     "iopub.status.busy": "2024-03-20T11:37:37.620065Z",
     "iopub.status.idle": "2024-03-20T11:37:41.977022Z",
     "shell.execute_reply": "2024-03-20T11:37:41.975309Z",
     "shell.execute_reply.started": "2024-03-20T11:37:37.620581Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip --quiet install langchain langchain-community langchain-openai chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5d3042-c378-49fc-bfd3-f1c97fa737d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:21.143803Z",
     "iopub.status.busy": "2024-03-20T11:37:21.142971Z",
     "iopub.status.idle": "2024-03-20T11:37:22.674959Z",
     "shell.execute_reply": "2024-03-20T11:37:22.674258Z",
     "shell.execute_reply.started": "2024-03-20T11:37:21.143752Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import Language\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48ac494f-add5-4968-bd2e-031ae0c7599d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T14:18:19.510441Z",
     "iopub.status.busy": "2024-03-20T14:18:19.509912Z",
     "iopub.status.idle": "2024-03-20T14:18:19.549354Z",
     "shell.execute_reply": "2024-03-20T14:18:19.548461Z",
     "shell.execute_reply.started": "2024-03-20T14:18:19.510398Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    docs = [Document(page_content=x) for x in text_splitter.split_text(text)]\n",
    "    return docs\n",
    "\n",
    "def embed_texts_openai(texts, openai_api_key):\n",
    "    print(f\"Embedding {len(texts)} texts...\", end=' ')\n",
    "    # Instantiate an embedder\n",
    "    embedder = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "    # Use the embedder to populate a Chroma vector store with our texts.\n",
    "    doc_search = Chroma.from_documents(texts, embedder)\n",
    "    print(\"✅\")\n",
    "    return doc_search\n",
    "\n",
    "def run_qa(doc_search, prompt, openai_api_key):\n",
    "    print(f\"Running QA...\", end=' ')\n",
    "\n",
    "    # Retrieval QA\n",
    "    # - chain_type=\"stuff\": the model 'stuffs' all our texts into a single prompt (sufficiently small)\n",
    "    # - model: latest GPT-3.5-Turbo model.\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=openai_api_key),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=doc_search.as_retriever(search_kwargs={\"k\": 1})  # 1 doc to return max\n",
    "    )\n",
    "\n",
    "    answer = qa.invoke(prompt)\n",
    "    print(\"✅\")\n",
    "    return answer[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7386264a-edcb-47fb-b2db-5a246beb67c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:37:58.353034Z",
     "iopub.status.busy": "2024-03-20T11:37:58.352491Z",
     "iopub.status.idle": "2024-03-20T11:37:58.386714Z",
     "shell.execute_reply": "2024-03-20T11:37:58.385434Z",
     "shell.execute_reply.started": "2024-03-20T11:37:58.352989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Maybelline Instant Age Rewind Eraser Dark Circles Treatment Concealer')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPEN_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "PRODUCT_INPUT = 'Maybelline Instant Age Rewind Eraser Dark Circles Treatment Concealer'\n",
    "\n",
    "\n",
    "chunks = get_text_chunks(PRODUCT_INPUT)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c85129-e9a4-4695-b2d8-1056bc785471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:38:01.350364Z",
     "iopub.status.busy": "2024-03-20T11:38:01.349077Z",
     "iopub.status.idle": "2024-03-20T11:38:05.328487Z",
     "shell.execute_reply": "2024-03-20T11:38:05.327445Z",
     "shell.execute_reply.started": "2024-03-20T11:38:01.350157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1 texts... ✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x1157524a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_search = embed_texts_openai(chunks, OPEN_API_KEY)\n",
    "doc_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be74c13c-8b0d-44ab-bf19-bdd59a903028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:38:05.331003Z",
     "iopub.status.busy": "2024-03-20T11:38:05.330539Z",
     "iopub.status.idle": "2024-03-20T11:38:08.201325Z",
     "shell.execute_reply": "2024-03-20T11:38:08.199680Z",
     "shell.execute_reply.started": "2024-03-20T11:38:05.330921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running QA... ✅\n",
      "Product: Maybelline Instant Age Rewind Eraser Dark Circles Treatment Concealer\n",
      "\n",
      "Some rating criteria:\n",
      "1. Coverage (how well it conceals dark circles)\n",
      "2. Longevity (how long the concealer lasts without creasing or fading)\n",
      "3. Application (ease of application and blending)\n",
      "4. Shade range (variety of shades available)\n",
      "5. Packaging (convenience and effectiveness of the packaging)\n",
      "6. Skincare benefits (any improvements in the appearance of dark circles over time)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given this product title, please select between 3 and 6 criteria to rate in order to compose a product review.\n",
    "\"\"\"\n",
    "answer = run_qa(doc_search, prompt, OPEN_API_KEY)\n",
    "\n",
    "print(f\"Product: {PRODUCT_INPUT}\\n\")\n",
    "print(f\"Some rating criteria:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88107a0a-59c3-4091-a4df-b8e9b56591f2",
   "metadata": {},
   "source": [
    "### B) Langchain - all products and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddfb4f34-55d8-47b7-8e46-32c61e6ee911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:42:43.680982Z",
     "iopub.status.busy": "2024-03-20T11:42:43.680232Z",
     "iopub.status.idle": "2024-03-20T11:42:43.760636Z",
     "shell.execute_reply": "2024-03-20T11:42:43.759863Z",
     "shell.execute_reply.started": "2024-03-20T11:42:43.680927Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.streaming_stdout_final_only import FinalStreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ad78e-abc6-478b-b365-e769bef0049a",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773cf3b6-0d1d-440e-81e6-be9b62fc5776",
   "metadata": {},
   "source": [
    "Pick a model from the \"Model Explorer\" section on the [GPT4All page](https://gpt4all.io/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab79495-84e9-493c-8638-8438023c8543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:42:16.776767Z",
     "iopub.status.busy": "2024-03-20T11:42:16.776138Z",
     "iopub.status.idle": "2024-03-20T11:42:17.475750Z",
     "shell.execute_reply": "2024-03-20T11:42:17.473852Z",
     "shell.execute_reply.started": "2024-03-20T11:42:16.776722Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Resuming transfer from byte position 4108928128\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 27242    0 27242    0     0  76073      0 --:--:-- --:--:-- --:--:-- 76094\n",
      "total 8025256\n",
      "-rw-r--r--  1 joannerobert  staff   3.8G Mar 20 12:12 mistral-7b-openorca.gguf2.Q4_0.gguf\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'mistral-7b-openorca.gguf2.Q4_0.gguf'  # Change here\n",
    "MODEL_PATH = '../models/' + MODEL_NAME\n",
    "\n",
    "# -C - option to continue transfer automatically (so reuse file if already downloaded)\n",
    "!curl -C - -o {MODEL_PATH} https://gpt4all.io/models/gguf/{MODEL_NAME}\n",
    "!ls -lh ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de57f517-d056-4736-ac6c-5eca117822a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T11:42:46.349295Z",
     "iopub.status.busy": "2024-03-20T11:42:46.348501Z",
     "iopub.status.idle": "2024-03-20T11:43:01.445451Z",
     "shell.execute_reply": "2024-03-20T11:43:01.444610Z",
     "shell.execute_reply.started": "2024-03-20T11:42:46.349240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT4All(verbose=True, callbacks=[<langchain.callbacks.streaming_stdout_final_only.FinalStreamingStdOutCallbackHandler object at 0x115753e50>], model='../models/mistral-7b-openorca.gguf2.Q4_0.gguf', client=<gpt4all.gpt4all.GPT4All object at 0x116c52200>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callback that supports token-wise streaming but will only return the final output\n",
    "# rather than intermediary steps\n",
    "callbacks = [FinalStreamingStdOutCallbackHandler()]\n",
    "\n",
    "# verbose=True is required for the callback manager\n",
    "llm = GPT4All(model=MODEL_PATH, callbacks=callbacks, verbose=True)\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21c731-2e6f-42af-95a9-0a2d0f1374d2",
   "metadata": {},
   "source": [
    "#### LLM chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280293a-30be-4548-9084-faeea739d01c",
   "metadata": {},
   "source": [
    "| Prompts |\n",
    "| :--- |\n",
    "| Given this product title, please select between 3 and 6 criteria to rate in order to compose a product review. |\n",
    "| Given this product title, please select between 3 and 6 criteria to rate in order to compose a product review.<br>Do not provide more criteria and don't add any more text. Do not write any review.|\n",
    "| Given this product title, please produce between 3 and 6 criteria to rate in order to compose a product review.<br>The answer should be in the format:<br>1. <1st criterium><br>2. <2nd criterium><br>...|\n",
    "| For this product, please produce between 3 and 6 criteria that could be rated by a user for a review. No examples needed.\n",
    "| For this product, please produce between 3 and 6 criteria that could be rated by a user for a review. No more details needed. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3bc5ee1-4a0e-4b3e-bc49-ed422381cbdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:39:06.072924Z",
     "iopub.status.busy": "2024-03-20T12:39:06.071066Z",
     "iopub.status.idle": "2024-03-20T12:39:06.112117Z",
     "shell.execute_reply": "2024-03-20T12:39:06.109985Z",
     "shell.execute_reply.started": "2024-03-20T12:39:06.072854Z"
    }
   },
   "outputs": [],
   "source": [
    "# Best so far\n",
    "original_prompt = \"\"\"\n",
    "For this product, please produce between 3 and 6 criteria that could be rated by a user for a review. No more details needed.\n",
    "\"\"\"\n",
    "\n",
    "template = f\"\"\"Product: '{{product_text}}'\n",
    "{original_prompt}\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"product_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6920f033-e7b4-4668-99d5-1f51dcdbe805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:39:07.093065Z",
     "iopub.status.busy": "2024-03-20T12:39:07.092425Z",
     "iopub.status.idle": "2024-03-20T12:39:07.132431Z",
     "shell.execute_reply": "2024-03-20T12:39:07.131209Z",
     "shell.execute_reply.started": "2024-03-20T12:39:07.093010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['product_text'], template=\"Product: '{product_text}'\\n\\nFor this product, please produce between 3 and 6 criteria that could be rated by a user for a review. No more details needed.\\n\"), llm=GPT4All(verbose=True, callbacks=[<langchain.callbacks.streaming_stdout_final_only.FinalStreamingStdOutCallbackHandler object at 0x115753e50>], model='../models/mistral-7b-openorca.gguf2.Q4_0.gguf', client=<gpt4all.gpt4all.GPT4All object at 0x116c52200>))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the LLM chain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, return_final_only=True)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "042a2547-1bec-4a81-9df7-021b1868d7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:39:07.549039Z",
     "iopub.status.busy": "2024-03-20T12:39:07.546533Z",
     "iopub.status.idle": "2024-03-20T12:39:51.538079Z",
     "shell.execute_reply": "2024-03-20T12:39:51.537071Z",
     "shell.execute_reply.started": "2024-03-20T12:39:07.549006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1) Coverage - How well does the concealer cover up dark circles?\n",
      "2) Consistency - Is it easy to apply or is it too thick/thin?\n",
      "3) Longevity - Does it last throughout the day without fading, creasing, or settling into fine lines?\n",
      "4) Shade Range - Are there enough shades available for different skin tones?\n",
      "5) Packaging - Is the packaging user-friendly and easy to use?\n",
      "6) Price - How affordable is this product compared to similar products on the market?\n",
      "CPU times: user 2min 50s, sys: 1.36 s, total: 2min 51s\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = llm_chain.run(product_text=PRODUCT_INPUT)\n",
    "# Note that the result needs to be printed explicitly to be shown properly since\n",
    "# it contains line returns\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad367fe-ffb3-4379-91f4-5d18fa539dd7",
   "metadata": {},
   "source": [
    "#### Retrieval QA chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a8326-d886-4974-94c7-5a9d5b602b97",
   "metadata": {},
   "source": [
    "##### Prompt only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a6852e8-84c4-4b8f-bb6c-39f733bd9725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T14:20:18.971261Z",
     "iopub.status.busy": "2024-03-20T14:20:18.970738Z",
     "iopub.status.idle": "2024-03-20T14:20:19.802242Z",
     "shell.execute_reply": "2024-03-20T14:20:19.801376Z",
     "shell.execute_reply.started": "2024-03-20T14:20:18.971219Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "PERSIST_DIRECTORY = '../db/chroma_3/'\n",
    "\n",
    "\n",
    "def embed_texts_hg(texts, openai_api_key):\n",
    "    print(f\"Embedding {len(texts)} texts...\", end=' ')\n",
    "    \n",
    "    embedder = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    vector_db = Chroma.from_documents(\n",
    "        docs=texts, \n",
    "        embedding=embedder,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    print(\"✅\")\n",
    "    return vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c791daa-c99c-4f0c-b6d9-68ee36d10c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks = get_text_chunks(PRODUCT_INPUT)\n",
    "# chunks\n",
    "\n",
    "# doc_search = embed_texts_openai(chunks, OPEN_API_KEY)\n",
    "# doc_search\n",
    "\n",
    "# def run_qa(doc_search, prompt, openai_api_key):\n",
    "#     print(f\"Running QA...\", end=' ')\n",
    "\n",
    "#     # Retrieval QA\n",
    "#     # - chain_type=\"stuff\": the model 'stuffs' all our texts into a single prompt (sufficiently small)\n",
    "#     # - model: latest GPT-3.5-Turbo model.\n",
    "#     qa = RetrievalQA.from_chain_type(\n",
    "#         llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=openai_api_key),\n",
    "#         chain_type=\"stuff\",\n",
    "#         retriever=doc_search.as_retriever(search_kwargs={\"k\": 1})  # 1 doc to return max\n",
    "#     )\n",
    "\n",
    "#     answer = qa.invoke(prompt)\n",
    "#     print(\"✅\")\n",
    "#     return answer[\"result\"]\n",
    "    \n",
    "\n",
    "# prompt = \"\"\"\n",
    "# Given this product title, please select between 3 and 6 criteria to rate in order to compose a product review.\n",
    "# \"\"\"\n",
    "# answer = run_qa(doc_search, prompt, OPEN_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455a0b7-50c6-45c3-aa67-ea36a1b852fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading from actual files\n",
    "\n",
    "# def load_file(file_path):\n",
    "#     print(f\"Loading {file_path}...\", end=' ')\n",
    "#     try:\n",
    "#         loader = TextLoader(file_path)\n",
    "#         documents = loader.load()\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"File not found: {file_path}\")\n",
    "#         return\n",
    "\n",
    "#     # A) Recursive splitter\n",
    "#     splitter = (RecursiveCharacterTextSplitter\n",
    "#                 .from_language(language=Language.PYTHON, chunk_size=2000, chunk_overlap=200))\n",
    "#     # B) Text splitter\n",
    "#     # splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "#     texts = splitter.split_documents(documents)\n",
    "#     print(\"✅\")\n",
    "#     return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d784e969-f4d2-4c5b-bbf0-896cbbc6a617",
   "metadata": {},
   "source": [
    "## Results analysis\n",
    "\n",
    "\n",
    "Generate outputs for many products, analyse results to validate patterns, look out for exceptions, derive a safe criteria extraction method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
